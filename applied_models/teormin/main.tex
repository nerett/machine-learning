\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[T2A]{fontenc}    
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}

\usepackage{amsmath}

\renewcommand{\sfdefault}{cmss}
\renewcommand{\rmdefault}{cmr}
\renewcommand{\ttdefault}{cmt}

\title{Теоретический минимум по машинному обучению (Поток Воронцов К.В. и Грабовой А.В.)}
\author{Константин Вихлянцев \\ Андрей Цедрик \\ Алексей Алексеев \\ Иван Мартынов}
\date{\today}

\begin{document}

\maketitle

\newpage

\section{Решающие деревья}
\begin{enumerate}
    \item \textbf{Что такое решающее дерево и как оно работает?} Решающее дерево -- это модель, которая рекурсивно разбивает множество объектов на подмножества, принимая решения в узлах на основе признаков, чтобы предсказать класс (или значение) в листьях.
    \item \textbf{Какие критерии для выбора параметров в узлах дерева, какой из какого следует и почему?} Для классификации применяются энтропия и индекс Джини (оба измеряют неоднородность классов), а для регрессии -- среднеквадратичная ошибка (\texttt{MSE}); выбор критерия зависит от задачи, но все они направлены на уменьшение неоднородности в поддеревьях.
    \item \textbf{Какие гиперпараметры регулируют сложность решающего дерева?} Глубина дерева (\texttt{max\_depth}), минимальное количество объектов в узле для разделения (\texttt{min\_samples\_split}), минимальное количество объектов в листе (\texttt{min\_samples\_leaf}) и максимальное количество признаков при разбиении (\texttt{max\_features}).
    \item \textbf{Как решающие деревья обрабатывают задачи регрессии?} Дерево предсказывает среднее значение целевой переменной среди объектов в листе и строится с целью минимизации \texttt{MSE}.
    \item \textbf{В чем разница между классификационным и регрессионным деревом?} Классификационное дерево предсказывает категории и использует меры неоднородности (энтропию, индекс Джини), а регрессионное -- числовые значения и минимизирует среднеквадратичную ошибку (\texttt{MSE}).
\end{enumerate}

\section{Логистическая регрессия}
\begin{enumerate}
    \item \textbf{Что такое логистическая регрессия и какую задачу она решает?} Логистическая регрессия -- это линейная модель для бинарной классификации, которая предсказывает вероятность принадлежности к классу через сигмоиду:
    $$
    \sigma(z) = \frac{1}{1 + e^{-z}},
    $$
    где $z = \beta_{1} \cdot x_1 + \beta_{2} \cdot x_2 + ... + \beta_{n} \cdot x_n + b$.
    \item \textbf{Как выглядит функция потерь в логистической регрессии?} Используется логарифмическая функция потерь (логлосс): \\
    $L = -\frac{1}{n}\sum_{i=1}^{n}[y_i\log\hat{p}_i + (1 - y_{i})\log(1 - \hat{p}_i)]$, \\
    где $\hat{p}_i$ -- предсказанная вероятность для объекта i.
    \item \textbf{Как оптимизируются параметры в логистической регрессии?} Через градиентный спуск или его варианты (\texttt{Adam}, \texttt{SGD}), так как логлосс -- выпуклая функция, но аналитического решения, как в линейной регрессии, нет.
    \item \textbf{Как обобщить логистическую регрессию на многоклассовую классификацию?} \texttt{OvR} (\texttt{One"=vs"=Rest}): обучается одна модель на каждый класс против остальных. \texttt{Softmax}"=регрессия (многоклассовая логистическая): одна модель сразу предсказывает вероятности для всех классов через \texttt{softmax}"=функцию (обобщение сигмоиды). \\
    Формула \texttt{softmax} для \texttt{K} классов:
    $$
    softmax(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K}e^{z_j}},
    $$
    где:
    \begin{itemize}
        \item $z_i$ -- логит (выход модели до применения \texttt{softmax}) для класса \texttt{i};
        \item $\sum_{j=1}^{K}e^{z_j}$ -- сумма экспонент всех логитов.
    \end{itemize}
    \item \textbf{Чем логистическая регрессия отличается от линейной?} Линейная регрессия предсказывает непрерывные значения, логистическая -- вероятности классов, используя сигмоиду и логлосс вместо \texttt{MSE}.
    \item \textbf{Какие метрики используются для оценки классификации?}
    \begin{itemize}
        \item \texttt{Accuracy}: доля верно предсказанных объектов.
        \item \texttt{Precision}: из всех предсказанных положительных -- сколько верных?
        \item \texttt{Recall}: из всех настоящих положительных -- сколько найдено?
        \item \texttt{F1"=score}: гармоническое среднее между \texttt{precision} и \texttt{recall}.
        \item \texttt{Log"-loss}: средняя логарифмическая ошибка -- штрафует за неправильные уверенные предсказания.
    \end{itemize}
    \item \textbf{Что такое матрица ошибок?} Это таблица 2×2 (или \texttt{n}×\texttt{n}) где по строкам -- истинные классы, по столбцам -- предсказанные, показывающая, как модель путает классы.
\end{enumerate}

\section{SVM (Support Vector Machines)}
\begin{enumerate}
    \item \textbf{В чем основная идея SVM?} Основная идея \texttt{SVM} -- найти такую гиперплоскость, которая максимально разделяет классы, то есть имеет наибольший зазор (\texttt{margin}) между ближайшими точками двух классов.
    \item \textbf{Как строится разделяющая гиперплоскость в SVM?} \texttt{SVM} находит гиперплоскость, которая максимизирует отступ до ближайших объектов каждого класса (опорных векторов), решая задачу квадратичной оптимизации.
    \item \textbf{Зачем в SVM используются ядра?} Когда классы не разделимы линейной границей, мы можем отобразить данные в более высокоразмерное пространство, где они станут линейно разделимыми. Это делается неявно с помощью ядровой функции $K(x,x')$, которая вычисляет скалярное произведение в этом новом пространстве, не создавая его явно (\texttt{kernel trick}).
    \item \textbf{Назовите основные ядра в SVM.}
    \begin{itemize}
        \item Линейное (\texttt{linear});
        \item Полиномиальное (\texttt{polynomial});
        \item Радиально-базисное (\texttt{RBF}, \texttt{Gaussian});
        \item Сигмоидное (\texttt{sigmoid}).
    \end{itemize}
    \item \textbf{Как SVM обобщается для задач регрессии?} \texttt{Support Vector Regression (SVR)}. Вместо того чтобы находить гиперплоскость, разделяющую классы, \texttt{SVR} ищет функцию, максимально приближенную к данным, но допускает небольшие отклонения -- в пределах заданного параметра $\varepsilon$ (эпсилон). То есть модель не наказывается за небольшие ошибки, а штрафует только те, что выходят за $\varepsilon$"=интервал.
    \item \textbf{Как работает метод опорных векторов для несбалансированных данных?} Для несбалансированных данных можно использовать взвешивание классов: увеличить штраф за ошибку на меньшинстве, чтобы модель не игнорировала малочисленный класс при обучении.
\end{enumerate}

\section{Линейная регрессия}
\begin{enumerate}
    \item \textbf{Как работает линейная регрессия?} Линейная регрессия моделирует зависимость целевой переменной от признаков как линейную комбинацию признаков: $\hat{y}
 = X\beta+b$, где параметры подбираются для минимизации ошибки предсказания.
    \item \textbf{Как находится оптимальное значение параметров?} Оптимальные параметры находятся методом минимизации среднеквадратичной ошибки (\texttt{MSE}), обычно через аналитическое решение (МНК) или численно, например градиентным спуском.
    \item \textbf{В чем проблема мультиколлинеарности и как ее решают}? Мультиколлинеарность возникает, когда признаки линейно зависимы, из"=за чего коэффициенты становятся нестабильными; решается с помощью регуляризации (\texttt{Lasso, Ridge}) или удаления/объединения коррелирующих признаков.
    \item \textbf{Объясните вероятностную интерпретацию регуляризации в случае Lasso и Ridge.} \texttt{Lasso} соответствует лапласовскому априорному распределению на коэффициенты (более "острый" пик в нуле, стимулирующий обнуление коэффициентов), а \texttt{Ridge} -- гауссовскому априорному распределению (нулевое среднее, нормальное распределение).
    \item \textbf{Чем Lasso отличается от Ridge регуляризации?} \texttt{Lasso} использует $L_1$"=норму и может занулять коэффициенты, выполняя отбор признаков; \texttt{Ridge} использует $L_2$"=норму и только уменьшает веса, не обнуляя их.
    \item \textbf{Как оценивать качество регрессионных моделей?} Основные метрики: \texttt{MSE}, \texttt{RMSE} (\texttt{Root MSE}), \texttt{MAE} (средняя абсолютная ошибка).
\end{enumerate}

\section{Ансамблирование моделей}
\begin{enumerate}
    \item \textbf{Назовите основные виды ансамблирования и их основное отличие.}
    \begin{itemize}
        \item Бэггинг -- строит модели независимо и усредняет (уменьшает дисперсию);
        \item Бустинг -- строит модели последовательно, каждая исправляет ошибки предыдущей (уменьшает смещение);
        \item Стекинг -- обучает метамодель на предсказаниях базовых моделей.
    \end{itemize}
    \item \textbf{Когда лучше использовать бэггинг, а когда — бустинг?}
    \begin{itemize}
        \item Бэггинг -- когда модель переобучается (например, решающие деревья);
        \item Бустинг -- когда модель недообучена и нужно снизить смещение.
    \end{itemize}
    \item \textbf{Приведите примеры алгоритмов бустинга.}
    \begin{itemize}
        \item \texttt{Gradient Boosting}
        \item \texttt{XGBoost}
    \end{itemize}
    \item \textbf{Приведите примеры алгоритмов бэггинга.}
    \begin{itemize}
        \item \texttt{Random Forest}
        \item \texttt{Extra Trees}
    \end{itemize}
    \item \textbf{Как работает алгоритм Random Forest?} \texttt{Random Forest} -- это ансамбль решающих деревьев, обученных на разных подвыборках данных и случайных подмножествах признаков; итоговое предсказание -- голосование (классификация ) или усреднение (регрессия).
    \item \textbf{Объясните принцип работы XGBoost.} \texttt{XGBoost} строит деревья последовательно, минимизируя дифференцируемую функцию потерь с регуляризацией; использует продвинутые оптимизации (обрезку деревьев, параллелизм, кэширование) для высокой производительности.
    \item \textbf{Что такое ``ансамблевое усреднение''?} Это способ объединения предсказаний нескольких моделей путем голосования (для классификации) или простого усреднения (для регрессии).
    \item \textbf{Как работает метод Stacking в ансамблировании?} \texttt{Stacking} обучает несколько моделей (базовый уровень), собирает их предсказания, а затем обучает финальную модель (мета"=уровень) на этих предсказаниях.
    \item \textbf{Как работает метод случайного подпространства (Random Subspace) в бэггинге?} Каждая модель обучается не только на случайной подвыборке объектов, но и на случайном подмножестве признаков, что повышает разнообразие и устойчивость ансамбля.
\end{enumerate}

\section{Отбор признаков}
\begin{enumerate}
    \item \textbf{Какие методы отбора признаков вы знаете?} 
    \begin{itemize}
        \item Фильтрационные методы работают независимо от модели и используют статистические меры для оценки значимости признаков.
        \item Обёрточные методы оценивают подмножества признаков на основе качества модели, что обеспечивает высокую точность, но увеличивает вычислительную сложность (например, полный перебор).
        \item Эвристические и случайные методы используют эвристики или случайный подход для нахождения подмножеств признаков, что снижает вычислительную сложность (например, генетический алгоритм).
    \end{itemize}
    \item \textbf{Почему L1"=регуляризация зануляет некоторые параметры?} В \texttt{L1}"=регуляризации допустимая область решений -- это ромб (в \texttt{2D}). А уровни функции потерь (например, квадратичной) -- это эллипсы. Оптимум находится в точке касания эллипса и ромба. Чаще всего это угловая точка ромба, где один из коэффициентов равен нулю.
    \item \textbf{Как работает жадный алгоритм Add-Del для отбора признаков?} 
    \begin{enumerate}
        \item Хранит и пытается заполнить множество оптимальных признаков. Состоит из двух фаз:
            \begin{enumerate}
                \item \texttt{add}: в мн-во добавляется признак, максимально улучшающий метрику эффективности, улучшение должно быть выше порога (по очереди перебираются все признаки и переобучается модель);
                \item \texttt{del}: то же, но из оптимального набора удаляется признак, наименее сильно ухудшающий модель.
            \end{enumerate}
        \item Переключение фаз либо по количеству шагов на каждой из них, либо по порогу изменения метрики. 
        \item Остановка если модель не меняется при применении фаз (уже все найдено), если набрано нужное кол-во признаков, если пройдено макс кол-во итераций, если начинается переобучение
    \end{enumerate}
    \item \textbf{Объясните критерий Фишера для отбора признаков.} Метод отбора признаков, используемый в задачах классификации. Его основная идея заключается в оценке, насколько хорошо каждый отдельный признак способен разделять данные на различные классы. Для 2 классов: $ F = \frac{(\mu_1 - \mu_2)^2}{\sigma_1^2 + \sigma_2^2}$, где используются средние значения и стд признака по соответствующим классам. Если разница среднего большая => признак полезный. Для нескольких классов $ F = \frac{  \Sigma_j n_j (\mu_j - \mu)^2}{\Sigma_j n_j \sigma_j^2} $, n - кол-во элементов в классе, $\mu$ - по всей выборке.
    \item \textbf{Как метод Белсли и SVD помогают бороться с мультиколлинеарностью?} 
    \begin{enumerate}
        \item Синглуярное разложение:  если одно или несколько сингулярных значений близки к нулю, это указывает на то, что столбцы матрицы \texttt{X} (т.е. признаки) почти линейно зависимы. Чем меньше сингулярное значение, тем сильнее коллинеарность. Вместо регрессии на исходные коррелированные признаки, регрессия строится на наборе некоррелированных (ортогональных) главных компонент. Главные компоненты -- это линейные комбинации исходных признаков, которые соответствуют правым сингулярным векторам
        \item Метод Белсли считает индексы обусловленности (отношение максимального сингулярного значения к каждому сингулярному значению): 
        \begin{enumerate}
            \item если индексы большие (обычно > 30), то есть серьезные проблемы с мультиколлинеарностью; если маленькие их скорее всего нет, если очень большие (>100) то мультиколлинеарность почти идеальная. 
            \item Для интерпретации сингулярных чисел используют доли разложения дисперсии: показывают, какая часть дисперсии оценки каждого коэффициента регрессии связана с каждым сингулярным значением (и, следовательно, с каждым индексом обусловленности). Если высокий индекс обусловленности ассоциируется с высокими долями разложения дисперсии (например, > 0.5) для двух или более коэффициентов регрессии, это является сильным свидетельством того, что эти переменные вовлечены в коллинеарную связь, породившую данный высокий индекс.
        \end{enumerate}
    \end{enumerate}
\end{enumerate}

\section{Деление выборки}
\begin{enumerate}
    \item \textbf{В чем проблемы случайного деления выборки на обучение и контроль?} 
    \begin{enumerate}
        \item Нет гарантии, что обучающая и тестовая выборки будут в полной мере представлять общую совокупность данных;
        \item При случайном разбиении в тестовую или обучающую выборку может попасть недостаточное количество примеров редкого класса;
        \item Утечка данных: при работе с данными, имеющими временную или групповую структуру, могут утечь данные из теста в обучение (например, во временных данных случайное разбиение может поместить будущие данные в обучающую выборку, что даст модели информацию из ``будущего'', а на ``реально будущем'' такой информации нет и модель плохо себя покажет).
    \end{enumerate}
    \item \textbf{Как стратификация решает проблему несбалансированных данных?} Это метод разделения набора данных, который гарантирует, что пропорциональное представительство определенных характеристик (страт) сохраняется в каждой создаваемой подвыборке. 
    \begin{enumerate}
        \item Весь набор данных делится на непересекающиеся подгруппы, называемые стратами. Они формируются на основе характеристики, которая считается важной для сохранения пропорций в конечных выборках (например принадлежность к классу).
        \item  Из каждой страты для обучающей и тестовой выборок производится независимая случайная выборка этого количества примеров.
    \end{enumerate}
    \item \textbf{Что такое утечка данных при разделении выборки?} См 2 вопроса выше, примеры (кроме времени): есть данные о покупках разных клиентах, если поделить клиента между  тестом и трейном, в модель будет зашита информация о его покупках что повысит результат теста, а на реальных данных не сработает;  использование мат ожидания и стд, полученных по полной выборке, тоже дает информацию из теста.
\end{enumerate}

\section{Нейронные сети}
\begin{enumerate}
    \item \textbf{Что такое полносвязная нейронная сеть?} Сеть состоит из слоев нейронов, где каждый нейрон одного слоя соединен со всеми нейронами предыдущего слоя и передает свой выходной сигнал всем нейронам следующего слоя. Нейрон принимает взвешенную сумму входных сигналов и применяет к ней функцию активации.
    \item \textbf{Назовите популярные функции активации, в чем их отличие.} 
    \begin{enumerate}
        \item Сигмоида $\frac{1}{1+e^{-x}}$ и  \texttt{tanh} $\frac{e^x+e^{-x}}{e^x+e^{-x}}$: сжимают выход в (-1, 1), страдают от проблемы исчезающего градиента; 
        \item \texttt{RELU} $max(0,x)$, \texttt{leaky RELY} $max(ax,x), a <<1$: полулинейные или кусочно-линейные, решают проблему исчезающего градиента для положительных значений, вычислительно эффективны, \texttt{leaky} решает проблемы исчезающего градиента; 
        \item \texttt{softmax}: применяется не к отдельному нейрону, а к целому слою (обычно выходному) и используется в основном на выходном слое для задач многоклассовой классификации.
    \end{enumerate}
    \item \textbf{Какие проблемы возникают в полносвязных сетях?} 
    \begin{enumerate}
        \item Большое количество параметров (долго обучать и возможно переобучение); 
        \item Обрабатывают входные данные как плоский вектор, полностью игнорируя их исходную структуру; 
        \item Проблема ``исчезающего/взрывающегося градиента'' (обучение нестабильное/медленное); 
        \item Черный ящик (непонятно как работает).
    \end{enumerate}
    \item \textbf{Что такое dropout, чем отличается в обучении и в контроле?} 
    \begin{enumerate}
        \item в обучении: для каждого слоя, к которому применяется \texttt{dropout}, для определенного процента нейронов их активации временно устанавливаются равными нулю; 
        \item в контроле: никто не выключается, но масштабируются коэффициенты на $(1 - dropout\_rate)$.
    \end{enumerate}
    \item \textbf{Что такое BatchNorm, чем отличается в обучении и в контроле?}  
    \begin{enumerate}
        \item \texttt{BatchNorm} нормализует входные данные каждого слоя, преобразуя их таким образом, чтобы они имели среднее $\approx 0$ и стд $\approx 1$. В отличие от  нормализации \textit{\textbf{входных}} данных, \texttt{BatchNorm} делает это динамически для выходов каждого слоя во время обучения;
        \item В обучении: считаем среднее и стд для каждого нейрона в текущем мини"=батче (запоминаем также их скользящее среднее), нормализуем и сдвигаем  с помощью двух обучаемых параметров: гамма и бета: $y=\gamma x + \beta$; 
        \item В контроле: то же, но используем посчитанное скользящее среднее и обученные коэффициенты.
    \end{enumerate}
    \item \textbf{Что такое паралич нейронной сети и как его избежать?} 
    \begin{enumerate}
        \item Градиент функций активаций маленький (для \texttt{sigma} и \texttt{tanh} актуально), из-за чего коэффициенты почти не обновляются. 
        \item Можно заменить активацию на \texttt{ReLU} и подобное.
        \item Нормализация входных данных или по батчу может сдвинуть значения ближе к нулю. 
        \item Использование оптимизаторов с адаптивной скоростью обучения, таких как \texttt{Adam} и \texttt{RMSprop} (подстраивают скорость обучения для каждого параметра индивидуально).
        \item Правильная инициализация весов.
        \item Уменьшение размера шага обучения (замедлит, но может убрать паралич).
    \end{enumerate}
    \item \textbf{Опишите идею обратного распространения ошибки в нейросетях.} 
    \begin{enumerate}
        \item Прямой проход: обычная работа сети;
        \item Подсчет лосс функции;
        \item Обратный проход: ошибка, вычисленная на выходном слое, ``распространяется'' обратно через сеть. На каждом слое вычисляется ``вклад'' каждого нейрона в эту ошибку. Для вычисления того, как изменение каждого отдельного веса влияет на конечную ошибку, используется цепное правило их исчисления (для подсчета градиента).
    \end{enumerate}
    \item \textbf{Опишите идею прямого метода дифференцирования в нейросетях.} Для каждой входной переменной, по которой мы хотим найти производную, мы приписываем ей ``тангенциальное'' значение, которое показывает направление дифференцирования (как правило, 1 для переменной, по которой дифференцируем, и 0 для остальных). Затем, по мере того как данные проходят через вычислительный граф нейронной сети (от входа к выходу), мы одновременно вычисляем как значение функции в каждом узле, так и значение производной в этом узле.
    \item \textbf{Что такое градиентный спуск и его варианты?} Градиент указывает направление наискорейшего роста функции. Градиентный спуск использует это свойство: алгоритм итеративно движется в направлении, противоположном градиенту в текущей точке (в направлении наискорейшего убывания функции). Каждый шаг приближает к минимуму функции. \\
    Варианты: 
    \begin{enumerate}
        \item Пакетный градиентный спуск: на каждом шаге градиент вычисляется по всему обучающему набору данных; 
        \item Стохастический градиентный спуск: на каждом шаге градиент вычисляется по одному случайно выбранному обучающему примеру; 
        \item Мини-пакетный градиентный спуск (очевидно); 
        \item Градиентный спуск с моментом: добавляет к текущему градиенту скользящее среднее прошлых значений.
    \end{enumerate}
\end{enumerate}

\section{RNN, LSTM, GRU}
\begin{enumerate}
    \item \textbf{Как работают рекуррентные нейронные сети?} Скрытое состояние нейрона (или слоя) на текущем шаге времени передается как дополнительный вход на следующем шаге времени: сеть сохраняет внутреннее состояние, которое служит своего рода краткосрочной памятью о предыдущих элементах последовательности.
    \item \textbf{Какие проблемы возникают при обучении RNN?} Трудности с обучением долгосрочных зависимостей. Например, из"=за маленького градиента, веса, с более ранних шагов времени, обновляются незначительно и сеть не учится на основе давней информации; также слишком большой градиент и нестабильность ниже описаны в вопросе про \texttt{gradient clipping}.
    \item \textbf{Как LSTM и GRU решают эти проблемы и какие проблемы?} 
    \begin{enumerate}
        \item \texttt{LSTM} решают проблемы \texttt{RNN} благодаря введению состояния ячейки (\texttt{cell state}) (в добавок к скрытому состоянию (\texttt{hidden})) и трех типов вентилей: 
        \begin{enumerate}
            \item входного (решает, какую новую информацию следует "запомнить");
            \item забывающего (решает, какую информацию из предыдущего состояния ячейки следует "забыть");
            \item выходного (решает, какую часть текущего состояния ячейки следует использовать в качестве скрытого состояния на следующем шаге).
        \end{enumerate}
        \item \texttt{GRU}: упрощенный \texttt{LSTM} без \texttt{cell state} (только \texttt{hidden}) и только два вентиля 
        \begin{enumerate}
            \item Вентиль обновления -- решает, какая часть предыдущего скрытого состояния должна быть сохранена, а какая часть нового кандидатного скрытого состояния должна быть добавлена; 
            \item Вентиль сброса -- игнорирует часть предыдущего состояния при подсчете нового.
        \end{enumerate}
    \end{enumerate}
    \item \textbf{Что такое Gradient Clipping и зачем он нужен?} Для борьбы с проблемой взрывающихся градиентов (градиенты могут резко возрастать в процессе обратного распространения ошибки во времени или через многочисленные слои, вызывая проскакивание минимума) -- просто ограничим значение координат градиента $[-C, C]$, либо нормируем сразу весь вектор чтобы его длина была меньше указанной.
\end{enumerate}

\section{Сверточные сети (CNN)}
\begin{enumerate}
    \item \textbf{В чем идея сверточных нейронных сетей?} Вместо обработки изображения попиксельно, \texttt{CNN} применяют к нему набор локальных фильтров (сверток) для всех его точек, что использует локальную связность (пиксели имеют отношение только к своим соседям) и инвариантность к сдвигу (одна и та же матрица везде применяется).
    \item \textbf{Что такое операция свертки, какие у нее есть параметры?} Для всех позиций на изображении высчитывается взвешенное среднее пикселей вокруг, где веса берутся из обучаемой матрицы. \\ Параметры: 
    \begin{enumerate}
        \item \texttt{Kernel Size} -- размер матрицы и кол-во пикселей которые берутся вокруг; 
        \item Шаг (\texttt{stride}) -- количество пикселей, на которое сдвигается фильтр после каждого применения; 
        \item Отступ (\texttt{padding}) -- определяет, добавляются ли нулевые пиксели по границам входных данных перед выполнением свертки; 
        \item Входное/выходное кол"=во каналов (для каждого канала своя матрица); 
        \item \texttt{dilation} -- расстояние между пикселями в свертке.
    \end{enumerate}
    \item \textbf{Какие слои кроме сверточных используются в \texttt{CNN}?} 
    \begin{enumerate}
        \item Макс"=пулинг (\texttt{Max Pooling}): из каждого ``окна'' (небольшой области) на входной карте признаков выбирается максимальное значение; 
        \item Средний пулинг (\texttt{Average Pooling}): из каждого ``окна'' вычисляется среднее значение; 
        \item Полносвязные слои после конвертации в \texttt{1D} вектор.
    \end{enumerate}
    \item \textbf{В чем особенность архитектуры ResNet?} В использовании так называемых остаточных соединений (\texttt{residual connections}) или пропускных соединений (\texttt{skip connections}). Это сделано из"=за проблемы деградации (отсутствие улучшения или даже ухудшение модели) при увеличении количества слоев из-за трудностей оптимизации очень глубоких структур, в частности, с проблемой затухания градиентов при обратном распространении ошибки. Идея остаточных соединений: вместо того чтобы каждый слой пытался напрямую выучить требуемое преобразование из входа в выход (H(x)), \texttt{ResNet} предлагает, чтобы слои выучивали остаточное отображение ($F(x)=H(x)-x$). Иными словами, слои учатся предсказывать разницу между желаемым выходом и входом блока. Выход такого ``остаточного блока'' тогда будет равен $F(x) + x$. Это решает: легче обучать преобразования близкие к тождественным. Пропускные соединения создают ``прямые пути'' для распространения градиентов во время обратного распространения ошибки.
    \item \textbf{Как дообучать предобученные модели под конкретную задачу?} Т. к. модель основные паттерны запомнила, достаточно заменить только последний(-ие) слои. Дообучать можно только свои крайние слои (данных мало и цели похожи), часть или все слои (в противном случае).
\end{enumerate}

\section{Автокодировщики и GAN}
\begin{enumerate}
    \item \textbf{Что такое автокодировщик и зачем он нужен?}
        Это нейросеть, которая обучается без учителя и используется для повышения или понижения размерности данных с их последующим восстановлением, выделения наиболее важных признаков. Состоит из энкодера, который переводит данные в латентное представление (\texttt{latent space}), и декодера, который восстанавливает данные из латентного представления.
    \item \textbf{Как линейный автокодировщик связан с PCA?}
        \texttt{PCA} (метод главных компонент) -- это статистический метод снижения размерности данных, который преобразует признаки в новый набор ортогональных (независимых) переменных, называемых главными компонентами. Линейный автокодировщик с \texttt{MSE}"=функцией потерь и линейными активациями математически эквивалентен \texttt{PCA}, так как оба метода находят оптимальное линейное подпространство для минимизации ошибки реконструкции. Разница лишь в способе оптимизации: \texttt{PCA} использует аналитическое решение (\texttt{SVD} (сингулярное разложение матрицы)), а автокодировщик -- градиентный спуск.\\
        \texttt{tl;dr} Линейный автокодировщик -- это нейросетевой аналог \texttt{PCA}, но с возможностью обобщения на нелинейные случаи.
    \item \textbf{Опишите принцип работы вариационного автокодировщика.}
        Дальше будет описание одной из наших задач. \texttt{VAE} состоит из энкодера и декодера: на входе \texttt{x} (\texttt{input dim}), внутри \texttt{z} и его параметры нормального распределения $\mu$ и $\sigma$ (\texttt{latent dim}), на выходе параметры распределения \texttt{x} ($2 * input dim$ в случае нормального распределения, т.к. параметров два). Получаем на вход \texttt{x}, с помощью линейной модели преобразуем в параметры распределения \texttt{z}, потом сэмплируем \texttt{z} (то есть получаем \texttt{z} из его параметров распределения), отсюда с помощью линейной модели получаем предсказанные параметры распределения \texttt{x}. Можно генерировать объекты, похожие на изначальные \texttt{x}, сэмплируя их из предсказанных параметров распределения. Функция потерь (\texttt{ELBO}) преследует цель максимизации нижней оценки \texttt{log}"=правдоподобия: $\mathcal{L}_{VAE} = \mathcal{L}_{reconstruction} + \mathcal{L}_{KL}$ (ошибка реконструкции + \texttt{KL}"=дивергенция).
    \item \textbf{Чем GAN отличается от автокодировщика?}
        \texttt{GAN} (генеративно-состязательная сеть) и автокодировщик решают разные задачи. \texttt{GAN} генерирует новые данные через соревнование генератора и дискриминатора: генератор создает \texttt{fake}"=данные из шума (например, изображения, фото людей), а дискриминатор пытается отличить \texttt{fake} от реальных данных (цель -- соревнование, где генератор учится обманывать дискриминатор). Автокодировщик сжимает и восстанавливает данные, полезен для очистки или снижения размерности. Генерация в \texttt{GAN} качественнее, но обучение сложнее, тогда как автокодировщики стабильнее, но выдают размытые результаты.
\end{enumerate}

\section{Обучение с подкреплением (RL)}
\begin{enumerate}
    \item \textbf{В чем основная идея обучения с подкреплением?}
        Это метод, где агент учится принимать решения через взаимодействие со средой, получая награды за правильные действия. Цель -- максимизировать совокупную награду, балансируя между исследованием новых действий и эксплуатацией известных стратегий. Можно сказать, что это частный случай обучения с учителем, где среда является неявным учителем, воздействующим на агента через слабую обратную связь (награды). Примеры: игры, робототехника, управление автономными системами.
    \item \textbf{Приведите пример задачи RL с байесовскими бандитами.}
        Задача байесовских бандитов -- это упрощенная модель \texttt{RL}, где агент выбирает между несколькими ``однорукими бандитами'' (слотами), каждый с неизвестным распределением наград. Используя байесовский подход, агент обновляет свои представления о вероятностях выигрыша и балансирует между исследованием (\texttt{exploration}) и эксплуатацией (\texttt{exploitation}). \\
        Постановка задачи: есть \texttt{K} бандитов, каждый выдает награду $r$ из своего распределения (например, Бернулли: $r ~ Bernoulli(p_i)$, где $p_i$ -- неизвестная вероятность успеха). Цель агента: максимизировать суммарную награду за \texttt{T} шагов.\\
        Пример: динамический выбор рекламного баннера с максимальной конверсией. Бандиты -- это две версии сайта (\texttt{A} и \texttt{B}), а награда -- конверсия (1 -- клик, 0 -- нет).
    \item \textbf{Как решается задача заплыва?}
        Задача решается с помощью алгоритмов обучения с подкреплением, где агент управляет телом с суставами в вязкой среде и обучается генерировать движения, обеспечивающие продвижение вперёд. Состояние включает углы и скорости суставов, действия -- крутящие моменты. Агент получает награду за скорость или расстояние, пройденное вперёд, и со временем оптимизирует свою стратегию действий. Для обучения используются алгоритмы:
        \begin{itemize}
            \item \texttt{Policy Gradient} -- обучает стратегию напрямую, улучшая вероятность полезных действий на основе полученных наград.
            \item \texttt{PPO (Proximal Policy Optimization)} -- улучшенная версия \texttt{policy gradient}, которая ограничивает слишком резкие обновления стратегии.
            \item \texttt{Actor"=Critic} -- сочетает две модели: \texttt{actor} (предлагает действия) и \texttt{critic} (оценивает их качество).
        \end{itemize}
\end{enumerate}

\section{Активное обучение}
\begin{enumerate}
    \item \textbf{Какие проблемы решает активное обучение?}
        Активное обучение решает проблемы нехватки размеченных данных, высокой стоимости разметки, небалансированных классов (если, например, какие-то классы в данных встречаются очень редко), неопределенности модели (модель не уверена).\\
        Пример с обучением алгоритма для робомобиля: cпециальная нейросеть обучается на уже размеченных данных, после этого обрабатывает неразмеченные данные, выбирая кадры, которые она не может распознать -- таким образом, она ищет данные, которые будут представлять трудность для целевого алгоритма. Затем эти данные изучаются и размечаются людьми, и добавляются в базу обучающих данных.
    \item \textbf{Назовите методы активного обучения.}
        \begin{itemize}
            \item \texttt{Uncertainty Sampling} (выбор по неопределенности) -- запрашивает примеры, в которых модель менее всего уверена.
            \item  \texttt{Query-by-Committee} (\texttt{QBC}, запрос по комитету) -- несколько моделей ("комитет") голосуют за спорные примеры.
            \item \texttt{Diversity Sampling} (выбор по разнообразию) -- отбирает разнообразные примеры, чтобы охватить все аспекты данных.
            \item \texttt{Expected Model Change} (ожидаемое изменение модели) -- выбирает примеры, которые сильнее всего изменят параметры модели.
            \item \texttt{Expected Error Reduction} (ожидаемое сокращение ошибки) -- выбирает примеры, которые максимально уменьшат ошибку модели.
            \item \texttt{Density-Weighted Methods} (методы с учетом плотности данных) -- комбинирует неопределенность и распределение данных.
        \end{itemize}
\end{enumerate}

\section{KNN (k-ближайших соседей)}
\begin{enumerate}
    \item \textbf{Как работает алгоритм KNN?}
        Он классифицирует или предсказывает значение объекта на основе \texttt{k} ближайших соседей из обучающей выборки. Для этого он вычисляет расстояния между объектами (например, евклидово) и выбирает наиболее частый класс (классификация) или среднее значение (регрессия) среди ближайших точек. \texttt{KNN} не обучает модель явно, а запоминает всю обучающую выборку.
    \item \textbf{Какие гиперпараметры есть у KNN (k, метрика расстояния)?}
        \begin{itemize}
            \item \texttt{k} (количество соседей) -- определяет, сколько ближайших точек учитывается при классификации/регрессии. Слишком малое \texttt{k} (например, 1) несёт высокий риск переобучения (чувствительность к шуму). Слишком большое \texttt{k} (например, 50) может приводить к сглаживанию границ (недообучению).
            \item Метрика расстояния -- определяет, как вычисляется расстояние между объектами:
                \begin{itemize}
                    \item Евклидово расстояние (подходит для непрерывных признаков)
                    $$
                        d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
                    $$
                    \item Манхэттенское расстояние (устойчивее к выбросам)
                    $$
                        d(x, y) = \sum_{i=1}^{n} |x_i - y_i|
                    $$
                    \item Косинусное расстояние (используется для текстовых данных или высокой размерности)
                    $$
                        \text{similarity}(x, y) = \frac{x \cdot y}{\|x\| \cdot \|y\|}
                    $$
                    \item Минковского (обобщение евклидова и манхэттенского (параметр \texttt{p}))
                    $$
                        d(x, y) = \left( \sum_{i=1}^{n} |x_i - y_i|^p \right)^{1/p}
                    $$
                \end{itemize}
            \item Веса соседей -- все соседи имеют одинаковый вес либо же вес обратно пропорционален расстоянию до объекта.
        \end{itemize}
    \item \textbf{Какие проблемы возникают при использовании KNN и как их решить?}
        Проблемы с набором возможных решений:
        \begin{itemize}
            \item Высокая вычислительная сложность (медленная работа на больших данных)
                \begin{itemize}
                    \item Оптимизированные структуры данных (\texttt{KD-Tree, Ball Tree}).
                    \item Снижение размерности (\texttt{PCA, t-SNE}).
                    \item Приближенные методы (\texttt{LSH}).
                \end{itemize}
            \item Чувствительность к шуму и выбросам (искажение расстояний из-за выбросов)
                \begin{itemize}
                    \item Увеличение \texttt{k}.
                    \item Взвешенное голосование.
                    \item Предобработка данных.
                \end{itemize}
            \item Необходимость нормировки признаков (доминирование признаков в разных масштабах)
                \begin{itemize}
                    \item Нормировка (\texttt{StandardScaler, MinMaxScaler}).
                    \item Косинусное расстояние.
                \end{itemize}
            \item Проклятие размерности (низкая информативность расстояний в многомерных пространствах)
                \begin{itemize}
                    \item Снижение размерности (\texttt{PCA, UMAP}).
                    \item Косинусное сходство.
                \end{itemize}
            \item Дисбаланс классов (предсказание доминирующего класса)
                \begin{itemize}
                    \item Взвешенное голосование.
                    \item Балансировка (\texttt{SMOTE}).
                \end{itemize}
            \item Выбор метрики расстояния (неправильная метрика снижает точность)
                \begin{itemize}
                    \item Тестирование метрик через кросс"=валидацию.
                    \item \texttt{TF-IDF} + Косинусное сходство для текстов.
                \end{itemize}
            \item Оптимальный выбор \texttt{k} (переобучение/недообучение)
                \begin{itemize}
                    \item Подбор \texttt{k} через \texttt{GridSearchCV}.
                    \item Эвристика \( k \approx \sqrt{n} \).
                \end{itemize}
        \end{itemize}
    \item \textbf{Как работает метод ближайших соседей для регрессии?}
        Метод ближайших соседей для регрессии предсказывает значение целевой переменной нового объекта, усредняя (или беря медиану) значения его \texttt{k} ближайших соседей из обучающей выборки. Алгоритм вычисляет расстояния между объектами, выбирает \texttt{k} ближайших точек и использует их целевую переменную для предсказания. Ключевые параметры: число соседей (\texttt{k}), метрика расстояния и веса (к примеру, обратные расстояния). Для устойчивости метода данные требуют нормировки.
\end{enumerate}

\section{Кластеризация}
\begin{enumerate}
    \item \textbf{Назовите методы кластеризации, чем они отличаются.}
        \begin{itemize}
            \item \textbf{K"=Means}: делит данные на сферические кластеры с центроидами. Требует задания числа кластеров, чувствителен к шуму.
            \item \textbf{DBSCAN}: группирует по плотности, работает с кластерами произвольной формы. Автоматически определяет число кластеров и игнорирует шум.
            \item \textbf{Иерархическая кластеризация}: строит дендрограмму для выбора числа кластеров. Подходит для вложенных структур, но вычислительно затратна.
            \item \textbf{GMM (Gaussian Mixture Models)}: моделирует данные как смесь гауссиан, поддерживает вероятностную принадлежность к кластерам.
            \item \textbf{Спектральная кластеризация}: эффективна для нелинейных данных, использует матрицу сходства и спектральные свойства.
            \item \textbf{Mean Shift}: автоматическое определение кластеров через плотность, настройка радиуса окна.
        \end{itemize}
        Различия:
        \begin{itemize}
            \item \textbf{Форма кластеров}: \texttt{K"=Means} -- сферические, \texttt{DBSCAN} и \texttt{Mean Shift} -- произвольные, \texttt{GMM} -- эллиптические.
            \item \textbf{Устойчивость к шуму}: \texttt{DBSCAN} явно помечает выбросы, \texttt{Mean Shift} игнорирует точки с низкой плотностью.
            \item \textbf{Число кластеров}: \texttt{K"=Means}, \texttt{GMM}, спектральная требуют задания числа, \texttt{DBSCAN}, \texttt{Mean Shift} и иерархическая определяют автоматически.
            \item \textbf{Сложность}: иерархическая и спектральная -- \(O(n^3)\), \texttt{K"=Means} -- \(O(n)\), \texttt{DBSCAN} -- \(O(n \log n)\), \texttt{Mean Shift} -- \(O(n^2)\).
        \end{itemize}
    \item \textbf{Какие методы не требуют задания числа кластеров?}
        \texttt{DBSCAN}, иерархическая кластеризация, \texttt{Mean Shift}. Пояснение: эти методы анализируют структуру данных (плотность, иерархию) для выявления естественного числа кластеров.
    \item \textbf{Как работает EM"=алгоритм в кластеризации?}
        \texttt{EM}"=алгоритм \\ (\texttt{Expectation-Maximization}) используется для поиска параметров вероятностных моделей, таких как \texttt{GMM}, где данные считаются порожденными несколькими распределениями. Он итеративно находит параметры распределений, максимизируя правдоподобие данных:
        \begin{itemize}
            \item \texttt{E}"=шаг: вычисляет вероятности принадлежности точек к кластерам через текущие параметры.
            \item \texttt{M}"=шаг: обновляет параметры (средние, ковариации, веса) кластеров на основе этих вероятностей.
        \end{itemize}
    \item \textbf{Как работает метод k"=средних?}
        Он группирует данные в \texttt{k} кластерах с центроидами, минимизируя сумму квадратов расстояний от точек до центров кластеров:
        \begin{enumerate}
            \item Инициализация: выбираются \texttt{k} случайных центроид.
            \item Назначение кластеров: каждая точка приписывается к ближайшей центроиде (евклидово расстояние).
            \item Обновление центроид: новый центроид = среднее всех точек кластера:
            $$
                \mu_k = \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i
            $$
            \item Повторение: шаги \texttt{b}-\texttt{c}, пока центроиды не стабилизируются или не достигнут максимум итераций.
        \end{enumerate}
    \item \textbf{Что такое матрица смежности в кластеризации?}
        Это квадратная матрица, где элемент $A_{ij}$ отражает близость или схожесть (смежность нод) между объектами $i$ и $j$. Она используется в алгоритмах, основанных на графах (например, спектральная кластеризация), чтобы представить данные как сеть связей.
    \item \textbf{Как работает метод DBSCAN?}
        Он группирует данные по плотности, используя параметры $\varepsilon$ (радиус окрестности) и $min\_samples$ (минимальное число точек в $\varepsilon$"=окрестности).
        \begin{itemize}
            \item Ядровые точки ($\geq min\_samples$ в $\varepsilon$-окрестности) образуют кластеры.
            \item Граничные точки присоединяются к кластерам, если находятся в $\varepsilon$"=окрестности ядровых.
            \item Шум -- точки вне кластеров.
        \end{itemize}
        Алгоритм находит ядровую точку, расширяет кластер, включая все достижимые точки через $\varepsilon$"=окрестности, повторяется для необработанных точек.
\end{enumerate}

\section{Тематическое моделирование}
\begin{enumerate}
    \item \textbf{Что такое тематическое моделирование и зачем оно нужно?} Тематическое моделирование (\texttt{topic modeling}) -- это метод автоматического выявления скрытых тем в текстовых данных. Оно помогает структурировать коллекции документов, находить основные темы и анализировать большие текстовые корпуса без ручной разметки.
    \item \textbf{Как EM"=алгоритм используется в тематическом моделировании?} \texttt{EM}"=алгоритм (\texttt{Expectation"=Maximization}) применяется для оценки скрытых параметров тематической модели, например в \texttt{LDA} (\texttt{Latent Dirichlet Allocation}).
    \begin{itemize}
        \item \texttt{E}"=шаг: рассчитываются вероятности принадлежности слов к темам.
        \item \texttt{M}"=шаг: обновляются распределения тем по словам и тем по документам.
    \end{itemize}
    \item \textbf{Примеры регуляризаторов в тематических моделях.} Регуляризаторы помогают сделать темы интерпретируемыми и устойчивыми. \\
    Примеры:
    \begin{itemize}
        \item \texttt{Sparsity} (разреженность): заставляет каждое слово принадлежать к небольшому числу тем.
        \item \texttt{Decorrelator} (декоррелятор): снижает схожесть между темами.
        \item \texttt{Smoothness} (сглаживание): делает распределения более равномерными.
    \end{itemize}
\end{enumerate}

\section{Ранжирование и поиск}
\begin{enumerate}
    \item \textbf{Зачем нужны ранжирующие системы?} Ранжирование упорядочивает документы по степени релевантности запросу. Это основа информационного поиска: цель -- показать пользователю наиболее полезные и соответствующие документы первыми.
    Ранжирование также применяется в рекомендательных системах, системах вопрос-ответ и др. задачах.
    \item\textbf{Как оценивают качество поисковых систем?} Используются специальные метрики ранжирования:
    \begin{itemize}
        \item \texttt{Precision@k} -- точность среди топ"=\texttt{k} результатов;
        \item \texttt{Mean Average Precision (MAP)} -- среднее по всем запросам значение средней точности;
        \item \texttt{NDCG (Normalized Discounted Cumulative Gain)} -- учитывает порядок и степень релевантности;
        \item \texttt{MRR (Mean Reciprocal Rank)} -- усреднённый обратный ранг первого релевантного результата.
    \end{itemize}
    Метрики могут быть бинарными (релевантен/нет) и градуированными (степень релевантности).
\end{enumerate}

\section{Трансформеры}
\begin{enumerate}
    \item \textbf{Что такое attention?} \texttt{Attention} -- механизм, позволяющий на каждом шаге обработки выделять наиболее значимые части входа. \\
    Формально: $attention(q, K, V) = softmax(qK^{\mathsf{T}} / \sqrt{d})V$, где \texttt{q} -- запрос, \texttt{K} -- ключи, \texttt{V} -- значения. \\
    Это позволяет учитывать весь контекст при генерации или обработке текста. В трансформерах используется \textbf{Multi"=Head Attention}, где вычисляются несколько attention"=механизмов параллельно.
    \item \textbf{В чем отличие между self"=attention и cross"=attention?} \\
    \textbf{Self"=attention} применяется внутри одного последовательного ввода: запросы, ключи и значения формируются из одного и того же источника (например, предложения). \\
    \textbf{Cross-attention} -- когда запросы берутся из одного источника (например, декодера), а ключи и значения -- из другого (например, энкодера). Это важно при генерации текста, перевода и \texttt{multi"=modal} задачах.
    \item \textbf{В чем отличие между transformer, gpt"=like и bert"=like моделями?}
    \begin{itemize}
        \item \texttt{Transformer} -- архитектура, включающая энкодер и декодер.
        \item \texttt{GPT (Generative Pretrained Transformer)} -- использует только декодер, обучается автогенеративно (\texttt{next token prediction}).
        \item \texttt{BERT} -- только энкодер, обучается маскированным языковым моделированием (\texttt{masked language modeling}).
    \end{itemize}
    \texttt{GPT} хорош в генерации, \texttt{BERT} -- в понимании текста.
    \item \textbf{На какие задачи обучался BERT в базовом варианте?}
    \begin{itemize}
        \item \texttt{Masked Language Modeling (MLM)} -- предсказание случайно замаскированных токенов.
        \item \texttt{Next Sentence Prediction (NSP)} — модель определяет, является ли второе предложение логическим продолжением первого.
    \end{itemize}
    Эти задачи позволяют \texttt{BERT} понимать контекст в обе стороны.
\end{enumerate}

\section{Другое}
\begin{enumerate}
    \item \textbf{Что такое метод главных компонент?} \texttt{PCA (Principal Component Analysis)} -- метод линейного понижения размерности. Он ищет ортогональные направления (главные компоненты), на которых проекция данных имеет наибольшую дисперсию. Это делается через разложение ковариационной матрицы на собственные вектора.
    \item \textbf{Что такое переобучение и как с ним бороться?} \texttt{Overfitting} -- ситуация, когда модель хорошо работает на обучающей выборке, но плохо -- на тестовой. Причина -- модель ``запоминает'' данные, а не обобщает.
    Способы борьбы: регуляризация (\texttt{L1}/\texttt{L2}), кросс"=валидация, ранняя остановка, аугментация данных, \texttt{dropout}.
    \item \textbf{В чем разница между параметрами и гиперпараметрами модели?}
    \begin{itemize}
        \item Параметры -- обучаются во время тренировки (например, веса нейронной сети).
        \item Гиперпараметры -- задаются до обучения (например, \texttt{learning rate}, число слоёв, регуляризация). Их подбирают через перебор или байесовскую оптимизацию.
    \end{itemize}
    \item \textbf{Что такое кросс"=валидация и зачем она нужна?} Кросс"=валидация -- способ оценки обобщающей способности модели.
    Самый известный -- \texttt{k"=fold}: данные делятся на \texttt{k} частей, каждая по очереди становится валидацией, остальные -- обучением. Среднее качество даёт устойчивую метрику.
    \item \textbf{Что такое ROC-кривая и AUC?}
    \begin{itemize}
        \item \texttt{ROC (Receiver Operating Characteristic) показывает} зависимость \texttt{TPR} от \texttt{FPR} при разных порогах классификации.
        \item \texttt{AUC (Area Under Curve)} -- площадь под \texttt{ROC}, чем ближе к 1, тем лучше. Это метрика качества бинарных классификаторов.
    \end{itemize}
    \item \textbf{Объясните разницу между байесовским и частотным подходами в ML.}
    \begin{itemize}
        \item Частотный подход: вероятность = частота в пределе бесконечных наблюдений. Модель оценивает параметры как единственные (\texttt{MLE}).
        \item Байесовский подход: вероятность = степень уверенности. Параметры -- случайные величины, используется априорное и апостериорное распределение.
    \end{itemize}
    \item \textbf{Наивный байесовский классификатор, что это такое?} Простая вероятностная модель на основе формулы Байеса с предположением независимости признаков. \\
    Работает удивительно хорошо для задач текстовой классификации (спам-фильтры, тональность и др.). \\
    $$
    P(C \mid x_1, x_2, \ldots, x_n) \propto P(C) \cdot \prod_{i=1}^{n} P(x_i \mid C)
    $$
    \item \textbf{Что такое ``проклятие размерности''?} С увеличением размерности пространство становится разреженным, метрики расстояний теряют смысл, увеличивается потребность в данных. Алгоритмы становятся менее устойчивыми и требуют больше времени и памяти. Особенно остро -- в \texttt{kNN} и решающих деревьях.
    \item \textbf{Как работает метод t-SNE для визуализации данных, в чем минусы?} \texttt{t-SNE} понижает размерность, моделируя вероятности близости точек и минимизируя дивергенцию (\texttt{KL}) между распределениями в исходном и целевом пространстве. \\
    Плюсы -- красивая визуализация кластеров. \\
    Минусы -- высокая сложность $O(N^2)$, плохо работает на больших данных, не сохраняет глобальную структуру, трудно интерпретируем.
    \item \textbf{Что такое обучение без учителя?} \texttt{Unsupervised learning} -- обучение на неразмеченных данных. Цели: кластеризация, понижение размерности, поиск аномалий. Методы: \texttt{K-Means}, \texttt{DBSCAN}, \texttt{PCA}, \texttt{Autoencoders}.
    \item \textbf{Какие задачи решает обучение с частичным привлечением учителя (semi"=supervised)?}
    \begin{itemize}
        \item Распознавание речи и текста: большинство аудиофайлов или текстов не размечены, но можно улучшить модель, используя их в обучении.
        \item Компьютерное зрение: классификация изображений, сегментация, обнаружение объектов — \texttt{semi"=supervised} подходы позволяют использовать большие наборы неразмеченных изображений.
        \item Обнаружение аномалий: часто только малая часть данных помечена как ``аномалия'', и \texttt{semi"=supervised} подход помогает лучше оценивать нормальность.
        \item Снижение переобучения: использование неразмеченных данных как регуляризатор -- модель не может ``запомнить'' все метки, когда их мало, и начинает учиться обобщать.
    \end{itemize}
    \item \textbf{Что такое Transfer Learning?} Перенос модели, обученной на одной задаче, на другую. Часто используется в \texttt{NLP} и \texttt{CV}: например, \texttt{BERT} обучается на большом корпусе, а потом дообучается на конкретной задаче (классификация, извлечение сущностей и т.д.).
    \item \textbf{Что такое "обучение с учителем" (supervised learning)?}
    \texttt{Supervised learning} -- обучение на размеченных данных (есть пары «вход — правильный ответ»). Цели: классификация, регрессия, ранжирование. Методы: логистическая регрессия, SVM, деревья решений, нейросети.
    \item \textbf{Что такое ``теория обучения'' (bias-variance tradeoff)?} Теория обучения описывает, как модель обобщает на новых данных, включая компромисс между смещением и дисперсией. Смещение -- это систематическая ошибка, дисперсия -- чувствительность к обучающей выборке. Хорошая модель должна сбалансировать оба. \\
    При увеличении сложности модели смещение уменьшается, но дисперсия растёт. И наоборот. Задача -- найти баланс между ними для минимальной общей ошибки.
\end{enumerate}

\end{document}
